{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Programming_PyTorch_05_Katya",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eistratova/PyTorch_programming_lessons/blob/main/Programming_PyTorch_05_Katya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmAaXlkY0zD5"
      },
      "source": [
        "# Programming PyTorch for Deep Learning\n",
        "Creating and Deploying Deep Learning Applications\"\n",
        "\n",
        "Ian Pointer\n",
        "\n",
        "Ссылка на материалы в GitHub: https://github.com/falloutdurham/beginners-pytorch-deep-learning\n",
        "\n",
        "Руководство по работе в Google Colab смотрите по [ссылке]( https://colab.research.google.com/notebooks/intro.ipynb#scrollTo=GJBs_flRovLc)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoRARFazYM3"
      },
      "source": [
        "# Глава 5. Классификация текстов.\n",
        "## Сентимент анализ твитов\n",
        "Дата-сеты для упражнения по классификации (сентимент анализ) твитов находятся по [ссылке](http://help.sentiment140.com/for-students)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZaOe9c5ZEE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e180f060-9e88-4a35-845a-19c1221396a7"
      },
      "source": [
        "# Подключение к Google-диску, где хранятся анные и будут сохраняться модели.\n",
        "# При запуске модуля будет показана ссылка - кликайте на неё и входите через свой аккаунт.\n",
        "# Копируйте ключ и вставьте его в окошко...\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtgbEFOyZg3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0798e31f-e38b-4c0e-d1a6-f9e9c6311f10"
      },
      "source": [
        "# Проверяем наличие доступа к директории, в которой будет сохраняться модель\n",
        "%cd '/gdrive/MyDrive/Colab_Notebooks/text_classification/trainingandtestdata'\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab_Notebooks/text_classification/trainingandtestdata\n",
            "testdata.manual.2009.06.14.csv             train-processed.csv\n",
            "training.1600000.processed.noemoticon.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0BBT0BK111o"
      },
      "source": [
        "dataset_dir = \"/gdrive/MyDrive/Colab_Notebooks/text_classification/trainingandtestdata/\"\n",
        "ready_data_dir = \"/gdrive/MyDrive/Colab_Notebooks/text_classification/preprocessed_data/\"\n",
        "# ready_data_dir = \"/content/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y4V7uA_w8Bk"
      },
      "source": [
        "# Pandas для предобработки данных\n",
        "import pandas as pd\n",
        "tweetsDF = pd.read_csv(dataset_dir+\"training.1600000.processed.noemoticon.csv\",engine=\"python\", header=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "kSNyKKND2gPb",
        "outputId": "5532752b-d0ac-44d3-b73e-7d7de8e4aa5d"
      },
      "source": [
        "print(tweetsDF[0].value_counts())\n",
        "tweetsDF.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    800000\n",
            "0    800000\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ...                                                  5\n",
              "0  0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1  0  ...  is upset that he can't update his Facebook by ...\n",
              "2  0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3  0  ...    my whole body feels itchy and like its on fire \n",
              "4  0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oorxa44g4VgS"
      },
      "source": [
        "#  Чтобы кодировать классы как числа, начинающиеся с 0, мы сначала создаем столбец типа category из столбца маркировки\n",
        "tweetsDF[\"sentiment_cat\"] = tweetsDF[0].astype('category')\n",
        "# Затем мы кодируем эти классы в виде числовой информации в другом столбце:\n",
        "tweetsDF[\"sentiment\"] = tweetsDF[\"sentiment_cat\"].cat.codes\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Jni51SVC6vVh",
        "outputId": "22d3b5b6-0337-4afd-e98f-4dcebdd7ebc0"
      },
      "source": [
        "# Смотрим, что получилось\n",
        "tweetsDF.head(5)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>sentiment_cat</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0           1  ... sentiment_cat sentiment\n",
              "0  0  1467810369  ...             0         0\n",
              "1  0  1467810672  ...             0         0\n",
              "2  0  1467810917  ...             0         0\n",
              "3  0  1467811184  ...             0         0\n",
              "4  0  1467811193  ...             0         0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__4_5Ulk6y6x",
        "outputId": "14275107-5238-40e1-9920-123a8e763034"
      },
      "source": [
        "# Смотрим, что получилось\n",
        "print(tweetsDF.tail(5))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         0           1  ... sentiment_cat sentiment\n",
            "1599995  4  2193601966  ...             4         1\n",
            "1599996  4  2193601969  ...             4         1\n",
            "1599997  4  2193601991  ...             4         1\n",
            "1599998  4  2193602064  ...             4         1\n",
            "1599999  4  2193602129  ...             4         1\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLL2UNHB6-4h"
      },
      "source": [
        "# Затем мы сохраняем измененный CSV в файл:\n",
        "tweetsDF.to_csv(ready_data_dir+\"train-processed.csv\", header=None, index=None)\n",
        "# Для быстрого тестирования выделяем небольшой дата-сет\n",
        "tweetsDF.sample(1000000).to_csv(ready_data_dir+\"train-processed-sample.csv\", header=None,index=None)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBPlveGkBVAc"
      },
      "source": [
        "Библиотека **torchtext** генерирует набор данных простым способом: вы говорите, что вам нужно, и она обрабатывает исходный CSV (или JSON). Для этого сначала определяем поля. Класс `Field` имеет значительное количество параметров, которые могут быть ему присвоены: https://torchtext.readthedocs.io/en/latest/data.html#field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhFELWOAyla"
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# from torchtext import data # так в книге, но тогда выдаётся ошибка для data.LabelField()\n",
        "# Работает нижеследующий вариант импорта модуля data\n",
        "from torchtext.legacy import data\n",
        "# в докумнтации Pyorch про legacy ничего нет\n",
        "# как я понял, в torchtext.legacy, находится старая версия модуля data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXqa2rbYDjOM",
        "outputId": "51c1ed00-6ddc-4fb4-aeed-355b9e347815"
      },
      "source": [
        "%%time\n",
        "# Нас интересуют только маркировки и текст твитов. Мы определяем их, используя тип данных Field\n",
        "LABEL = data.LabelField()\n",
        "TWEET = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm', lower=True) # в книге нет tokenizer_language='en_core_web_sm'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 539 ms, sys: 33 ms, total: 572 ms\n",
            "Wall time: 789 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3-ERIfD9TJW"
      },
      "source": [
        "# TabularDataset\n",
        "`class torchtext.data.TabularDataset(path, format, fields, skip_header=False, csv_reader_params={}, **kwargs)`\n",
        "\n",
        "Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n",
        "\n",
        "`__init__(path, format, fields, skip_header=False, csv_reader_params={}, **kwargs)`\n",
        "\n",
        "Create a TabularDataset given a path, file format, and field list.\n",
        "\n",
        "Parameters:\t\n",
        "* **path** (*str*) – Path to the data file.\n",
        "* **format** (*str*) – The format of the data file. One of “CSV”, “TSV”, or “JSON” (case-insensitive).\n",
        "* **fields** (*list(tuple(str, Field)*) – tuple(str, Field)]: If using a list, the format must be CSV or TSV, and the values of the list should be tuples of (name, field). The fields should be in the same order as the columns in the CSV or TSV file, while tuples of (name, None) represent columns that will be ignored.\n",
        "\n",
        "If using a dict, the keys should be a subset of the JSON keys or CSV/TSV columns, and the values should be tuples of (name, field). Keys not present in the input dictionary are ignored. This allows the user to rename columns from their JSON/CSV/TSV key names and also enables selecting a subset of columns to load.\n",
        "\n",
        "* **skip_header** (*bool*) – Whether to skip the first line of the input file.\n",
        "* **csv_reader_params** (*dict*) – Parameters to pass to the csv reader. Only relevant when format is csv or tsv. See https://docs.python.org/3/library/csv.html#csv.reader for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN8lIhVuDaC7",
        "outputId": "fb5fff16-6ba0-430a-95af-e6d890e36a71"
      },
      "source": [
        "%%time\n",
        "# После определения полей LABEL и TWEET нам нужно создать список, который свяжет их со списком строк в CSV\n",
        "fields = [('score',None), ('id',None),('date',None),('query',None),\n",
        "          ('name',None),('tweet', TWEET),('category',None),('label',LABEL)]\n",
        "\n",
        "# Вооружившись объявленными полями, мы используем TabularDataset, чтобы применить это определение к CSV:\n",
        "twitterDataset = data.TabularDataset(\n",
        "        path = ready_data_dir+\"train-processed-sample.csv\",\n",
        "        fields = fields,\n",
        "        format = \"csv\",\n",
        "        skip_header=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 32s, sys: 1.74 s, total: 2min 33s\n",
            "Wall time: 2min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpW_eMsZG1sT",
        "outputId": "026bb68f-4d1e-471b-d1dc-93e6d41cf878"
      },
      "source": [
        "# делим наборы данных на обучение, тестирование и верификацию с помощью метода split():\n",
        "(train, test, valid) = twitterDataset.split(split_ratio=[0.6,0.2,0.2])\n",
        "(len(train),len(test),len(valid))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600000, 200000, 200000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnJdciYWHHV1",
        "outputId": "513e80bf-58f4-4b67-ae0f-c186ec767edd"
      },
      "source": [
        "# пример, вытащенный из набора данных:\n",
        "vars(train.examples[4000])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '1',\n",
              " 'tweet': ['@abcoates',\n",
              "  'was',\n",
              "  'talking',\n",
              "  'about',\n",
              "  'the',\n",
              "  'swiftcommunity.net',\n",
              "  'homepage',\n",
              "  ' ',\n",
              "  '...',\n",
              "  'nice',\n",
              "  'idea',\n",
              "  'thought',\n",
              "  '...']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVKuVnFjZMQg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En_Y3k9WZKb-",
        "outputId": "446601ac-2c82-4f0d-907c-84f847264a6f"
      },
      "source": [
        "# создание словаря\n",
        "vocab_size = 30000\n",
        "TWEET.build_vocab(train, max_size = vocab_size)\n",
        "LABEL.build_vocab(train)\n",
        "TWEET.vocab.freqs.most_common(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 373546),\n",
              " ('!', 338428),\n",
              " ('.', 303988),\n",
              " (' ', 219864),\n",
              " ('to', 212227),\n",
              " ('the', 195814),\n",
              " (',', 181300),\n",
              " ('a', 142744),\n",
              " ('my', 118483),\n",
              " ('it', 113740)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZmoFIrgZTRL",
        "outputId": "443a4fe5-50b4-4a08-b50e-12033892a2b6"
      },
      "source": [
        "%%time\n",
        "\n",
        "device = \"cuda\"\n",
        "# создаём загрузчик данных\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_size = 32,\n",
        "    device = device,\n",
        "    sort_key = lambda x: len(x.tweet),\n",
        "    sort_within_batch = False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 541 µs, sys: 0 ns, total: 541 µs\n",
            "Wall time: 602 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzGnthNZYtN"
      },
      "source": [
        "## Our First LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_KEP3LoZaaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a751c0b7-fa8e-42d3-ce71-5b6e1ecf3946"
      },
      "source": [
        "# Создаём сеть из 3-ёх слоёв\n",
        "device = \"cuda\"\n",
        "class OurFirstLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
        "        super(OurFirstLSTM, self).__init__()\n",
        "    \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # 1-st layer wih dimention=300 (see below)\n",
        "        self.encoder = nn.LSTM(input_size=embedding_dim,  # one layer of the LSTM \n",
        "                hidden_size=hidden_size, num_layers=1)    # with dimention=100 (see below)\n",
        "        self.predictor = nn.Linear(hidden_size, 2)        # 3d  layer with 2 output\n",
        "\n",
        "    def forward(self, seq):\n",
        "        output, (hidden,_) = self.encoder(self.embedding(seq))\n",
        "        preds = self.predictor(hidden.squeeze(0))\n",
        "        return preds\n",
        "\n",
        "model = OurFirstLSTM(100,300, 30002)\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OurFirstLSTM(\n",
              "  (embedding): Embedding(30002, 300)\n",
              "  (encoder): LSTM(300, 100)\n",
              "  (predictor): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPtjk_KHZtVG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3FALvEUZq6S"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epochs, model, optimizer, criterion, train_iterator, valid_iterator):\n",
        "    for epoch in range(1, epochs+1):\n",
        "     \n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_iterator):\n",
        "            optimizer.zero_grad()\n",
        "            predict = model(batch.tweet)\n",
        "            loss = criterion(predict,batch.label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * batch.tweet.size(0)\n",
        "        training_loss /= len(train_iterator)\n",
        " \n",
        "        \n",
        "        model.eval()\n",
        "        for batch_idx,batch in enumerate(valid_iterator):\n",
        "            predict = model(batch.tweet)\n",
        "            loss = criterion(predict,batch.label)\n",
        "            valid_loss += loss.data.item() * batch.tweet.size(0)\n",
        " \n",
        "        valid_loss /= len(valid_iterator)\n",
        "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS_qk5ICx7vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b10e61d-e522-47c4-feac-47b2ff5f4593"
      },
      "source": [
        "train(15, model, optimizer, criterion, train_iterator, valid_iterator)        "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 23.12, Validation Loss: 13.70\n",
            "Epoch: 2, Training Loss: 22.92, Validation Loss: 13.81\n",
            "Epoch: 3, Training Loss: 22.71, Validation Loss: 12.49\n",
            "Epoch: 4, Training Loss: 22.24, Validation Loss: 12.35\n",
            "Epoch: 5, Training Loss: 22.24, Validation Loss: 13.15\n",
            "Epoch: 6, Training Loss: 22.33, Validation Loss: 13.23\n",
            "Epoch: 7, Training Loss: 22.08, Validation Loss: 13.20\n",
            "Epoch: 8, Training Loss: 22.19, Validation Loss: 13.53\n",
            "Epoch: 9, Training Loss: 22.23, Validation Loss: 13.16\n",
            "Epoch: 10, Training Loss: 22.23, Validation Loss: 13.10\n",
            "Epoch: 11, Training Loss: 22.23, Validation Loss: 13.18\n",
            "Epoch: 12, Training Loss: 22.15, Validation Loss: 12.45\n",
            "Epoch: 13, Training Loss: 22.02, Validation Loss: 13.61\n",
            "Epoch: 14, Training Loss: 22.02, Validation Loss: 12.30\n",
            "Epoch: 15, Training Loss: 22.03, Validation Loss: 12.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ1gyFnO_JVS"
      },
      "source": [
        "# Сохранение и загрузка модели\n",
        "\n",
        "Мы можем либо сохранить всю модель, используя `save`, либо только параметры, используя `state_dict`. \n",
        "Использование последнего обычно предпочтительнее, поскольку оно позволяет повторно использовать параметры, даже если структура модели изменяется (или применять параметры от одной модели к другой)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL2Mm7r-7aFR"
      },
      "source": [
        "# path for model save\n",
        "models_dir = \"/gdrive/MyDrive/Colab_Notebooks/text_classification/models_rnn\"\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cpJIBS_7y9E"
      },
      "source": [
        "# Saving Model as Book Chapter 4\n",
        "\n",
        "# cохранение текущих параметров и структуры модели\n",
        "torch.save(model, models_dir+\"/rnn-model\")     \n",
        "# это сохранение содержит карты параметров каждого слоя в модели\n",
        "torch.save(model.state_dict(), models_dir+\"/rnn-model-map-2\")    \n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxsN1qAvAMij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72b86e1-bdbc-49fe-e76b-1bb9f9d6e094"
      },
      "source": [
        "# создание модели\n",
        "# rnn2 = model() \n",
        "# загрузка сохранённой модели\n",
        "rnn2 = torch.load(models_dir+\"/rnn-model\")\n",
        "# загрузка карты параметров слоёв модели в переменную rnn2_state_dict\n",
        "rnn2_state_dict = torch.load(models_dir+\"/rnn-model-map-2\")\n",
        "# загрузка карты параметров слоёв модели в модель rnn2\n",
        "rnn2.load_state_dict(rnn2_state_dict)             "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u0M4_-0aDxw"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z207R8ekINyK"
      },
      "source": [
        "# model = torch.load(models_dir+\"/rnn-model\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff3ElOoeaE53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fc0109-fe80-49ff-921b-a6480af12624"
      },
      "source": [
        "%%time\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    categories = {0: \"Негатив\", 1:\"Позитив\"}\n",
        "    processed = TWEET.process([TWEET.preprocess(tweet)]) # preprocess() выполняет токенизацию на основе spaCy\n",
        "                                                         # process создаёт из токенов тензор\n",
        "    processed = processed.to(device)                     \n",
        "    # model.eval()\n",
        "    # return categories[model(processed).argmax().item()]\n",
        "    rnn2.eval()\n",
        "    return categories[rnn2(processed).argmax().item()]\n",
        "'''\n",
        "Тензорный элемент с наибольшим значением соответствует выбранному классу модели, \n",
        "поэтому мы используем argmax() для получения его индекса, \n",
        "а затем item() для преобразования этого тензора нулевой размерности в целое число Python, \n",
        "которое мы индексируем в нашем словаре categories.\n",
        "'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo-a5Kq5336X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4175796-3404-4f6e-b552-dd6f9d794e83"
      },
      "source": [
        "tweet = \"I love my country\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "20WG6p_HQzvh",
        "outputId": "79f503fe-8e0a-41b8-fed2-64c655ce430c"
      },
      "source": [
        "tweet = \"he hates dogs\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "16GtEfzfRNb4",
        "outputId": "9dce2feb-59cc-44b6-995f-b83e5629692e"
      },
      "source": [
        "tweet = \"sun is smiling\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Негатив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yggSu8HEUQiX",
        "outputId": "2f243e61-6e43-4b54-dcd3-fb858056f713"
      },
      "source": [
        "tweet = \"I abuse you\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IlOsCL1an6VR",
        "outputId": "c0c062b2-fa3e-4106-ccd3-3845e93de7ad"
      },
      "source": [
        "tweet = \"Russian President met with US President\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Негатив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q19vCkZ2ojtM",
        "outputId": "e1a33dd9-9234-4349-d686-d9d0aeacc082"
      },
      "source": [
        "tweet = \"US announced sanctions on Russia\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Негатив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CNPLOpMGqard",
        "outputId": "6f9fe101-7e12-4cb4-85f1-4192783e3d5b"
      },
      "source": [
        "tweet = \"an explosion thundered in the city\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SpQ5PIXUqiWi",
        "outputId": "fb408c84-ca60-45ec-dee6-bf11f930dd2a"
      },
      "source": [
        "tweet = \"Nice weather in Paris\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VAKCgfqHrNIr",
        "outputId": "153db85b-266a-47a4-dd44-b30d88cc748a"
      },
      "source": [
        "tweet = \"The war is over and there is peace\"\n",
        "classify_tweet(tweet)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Позитив'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9wF-qz4aKEe"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brVkQ462aRa9"
      },
      "source": [
        "def random_deletion(words, p=0.5):\n",
        "    if len(words) == 1:\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words))\n",
        "    if len(remaining) == 0:\n",
        "        return [random.choice(words)]\n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKJkyh09aWtp"
      },
      "source": [
        "def random_swap(sentence, n=5):\n",
        "    length = range(len(sentence))\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1]\n",
        "    return sentence"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvmTNtmaaZ16"
      },
      "source": [
        "# Note: you'll have to define remove_stopwords() and get_synonyms() elsewhere\n",
        "\n",
        "def random_insertion(sentence,n):\n",
        "    words = remove_stopwords(sentence)\n",
        "    for _ in range(n):\n",
        "        new_synonym = get_synonyms(random.choice(words))\n",
        "        sentence.insert(randrange(len(sentence)+1), new_synonym)\n",
        "    return sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeE2PJIttIHb",
        "outputId": "5ea20393-f9ad-4f71-b98a-a5fa3c036721"
      },
      "source": [
        "!pwd\n",
        "!mkdir /content/dataset\n",
        "!cd /content/dataset/\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘/content/dataset’: File exists\n",
            "/content\n",
            "dataset  ESC-50  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvESs9jxs3o5",
        "outputId": "deaaad47-2ab2-4b89-dcbb-5afcd3e13b9e"
      },
      "source": [
        "!git clone https://github.com/karoldvl/ESC-50\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ESC-50'...\n",
            "remote: Enumerating objects: 4154, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 4154 (delta 10), reused 0 (delta 0), pack-reused 4136\u001b[K\n",
            "Receiving objects: 100% (4154/4154), 878.78 MiB | 29.07 MiB/s, done.\n",
            "Resolving deltas: 100% (257/257), done.\n",
            "Checking out files: 100% (2011/2011), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPRBwxuafRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb3164b-f35e-4753-a414-62ed0e9e02a8"
      },
      "source": [
        "# Install googletrans version 3.1.0a0 (temporary fix for #57)\n",
        "!pip install googletrans==3.1.0a0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.5.30)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/b5/96947391e84e332010694ac8c4ba64841b90301ee0d05e7236ff934bb9f6/hstspreload-2021.7.5-py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.1MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp37-none-any.whl size=16368 sha256=0fdbe03d7912224dc60405cc340034f068e253c1de4215a79c8f5c09d48ca8b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "Successfully built googletrans\n",
            "Installing collected packages: sniffio, rfc3986, hpack, hyperframe, h2, h11, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.7.5 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I00MyxTAal4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41412538-20a1-44c6-be57-648d4e0e1bb0"
      },
      "source": [
        "import googletrans\n",
        "import random\n",
        "\n",
        "translator = googletrans.Translator()\n",
        "\n",
        "sentences = ['The cat sat on the mat']\n",
        "\n",
        "translations_fr = translator.translate(sentences, dest='fr')\n",
        "fr_text = [t.text for t in translations_fr] \n",
        "print(fr_text)   \n",
        "translations_en = translator.translate(fr_text, dest='en')\n",
        "en_text = [t.text for t in translations_en]\n",
        "print(en_text)   \n",
        "\n",
        "available_langs = list(googletrans.LANGUAGES.keys())\n",
        "tr_lang = random.choice(available_langs)\n",
        "print(f\"Translating to {googletrans.LANGUAGES[tr_lang]}\")\n",
        "\n",
        "translations = translator.translate(sentences, dest=tr_lang)\n",
        "t_text = [t.text for t in translations]\n",
        "print(t_text)\n",
        "\n",
        "translations_en_random = translator.translate(t_text, src=tr_lang, dest='en')\n",
        "en_text = [t.text for t in translations_en_random]\n",
        "print(en_text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Le chat s'est assis sur le tapis\"]\n",
            "['The cat sat on the carpet']\n",
            "Translating to xhosa\n",
            "['Ikati yayihleli emethini']\n",
            "['The cat was sitting on the mat']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}